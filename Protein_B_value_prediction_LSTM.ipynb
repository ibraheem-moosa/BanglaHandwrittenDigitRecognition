{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Protein_B-value_prediction_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ibraheem-moosa/BanglaHandwrittenDigitRecognition/blob/master/Protein_B_value_prediction_LSTM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Tnh9NCq61gBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8232aa7c-1f1e-4216-c619-0b7785ac180a"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5b526000 @  0x7f84dfd4a1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3q6PM2Ue16d7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d22c62a4-44a0-49a4-fbcb-620d027d8f7a"
      },
      "cell_type": "code",
      "source": [
        "accelerator"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cu80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "svnKgpFIFzkv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c27e2971-c7c9-4dc5-9280-5056f4e3cf0d"
      },
      "cell_type": "code",
      "source": [
        "platform"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cp36-cp36m'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "5MH5rLcyHm7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80ba7d78-5833-4c66-e2d0-bf5ad0d8bbac"
      },
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "vKYl33ZtPB7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e232a11-481c-4441-9bd9-2999c55f02b1"
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "NyRZTfBYPKW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94a375e9-f1dc-4022-9429-51a1ae2e7bb9"
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "cLvxVTUs3gBt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn.functional import relu\n",
        "from torch.nn.functional import leaky_relu\n",
        "from torch.nn.functional import dropout\n",
        "import numpy as np\n",
        "import torch.utils.data\n",
        "import scipy.sparse as scsp\n",
        "from bisect import bisect\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import pearsonr\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eKKTeSaJ3qxP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def summarize_tensor(tensor):\n",
        "    return torch.max(tensor).item(), torch.min(tensor).item(), torch.mean(tensor).item(), torch.std(tensor).item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xrK3hn8U3tB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  def close_event():\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zn7gvWJz48Nr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_true_and_prediction(y_true, y_pred):\n",
        "    fig = plt.figure()\n",
        "    timer = fig.canvas.new_timer(interval=10000)\n",
        "    timer.add_callback(close_event)\n",
        "    plt.title('Bidirectional, 8 Hidden States, 2 Output Layers')\n",
        "    plt.plot(y_pred, 'y-')\n",
        "    plt.plot(y_true, 'g-')\n",
        "    timer.start()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jda8Ywnl5AMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def summarize_nn(net):\n",
        "    print('##############################################################')\n",
        "    for name, param in net.named_parameters():\n",
        "        print('---------------------------------------------------------------')\n",
        "        print(name)\n",
        "        print(summarize_tensor(param))\n",
        "    print('##############################################################')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDMxDO0e5EEK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_avg_pcc(net, dataset, indices):\n",
        "    pcc = []\n",
        "    for i in indices:\n",
        "        x, y = dataset[i]\n",
        "        y_pred = net.predict(x)\n",
        "        y, y_pred = y.cpu(), y_pred.cpu()\n",
        "        for j in range(x.shape[0]):\n",
        "            pcc.append(pearsonr(y_pred.numpy()[j].flatten(), y.numpy()[j].flatten())[0])\n",
        "\n",
        "    pcc = np.array(pcc)\n",
        "    pcc[np.isnan(pcc)] = 0\n",
        "    return np.mean(pcc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ITPD6SOh5GsN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cross_validation(net, dataset, indices, k, threshold):\n",
        "    n = len(indices) // k\n",
        "    r = len(indices) - n * k\n",
        "    fold_lengths = [n + 1] * r + [n] * (k - r)\n",
        "    cumulative_fl = [0]\n",
        "    for fl in fold_lengths:\n",
        "        cumulative_fl.append(cumulative_fl[-1] + fl)\n",
        "    scores = []\n",
        "    for i in range(k):\n",
        "        print('Cross Validation Fold: {}'.format(i))\n",
        "        train_indices = []\n",
        "        validation_indices = []\n",
        "        for j in range(k):\n",
        "            if j == i:\n",
        "                validation_indices.extend(indices[cumulative_fl[j]:cumulative_fl[j+1]])\n",
        "            else:\n",
        "                train_indices.extend(indices[cumulative_fl[j]:cumulative_fl[j+1]])\n",
        "        train_pccs, validation_pccs = net.train(dataset, train_indices, validation_indices) \n",
        "        validation_pcc = max(validation_pccs)\n",
        "        scores.append(validation_pcc)\n",
        "        if validation_pcc < threshold:\n",
        "            break\n",
        "    return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72eBteNG5J_P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_param_config(param_grid, keys):\n",
        "    if len(keys) == 0:\n",
        "        yield None\n",
        "    else:\n",
        "        for value in param_grid[keys[0]]:\n",
        "            for rest_config in get_param_config(param_grid, keys[1:]):\n",
        "                yield keys[0], value, rest_config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d-Le--Hm5NL9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gridsearchcv(net, dataset, indices, k, threshold, param_grid, param_set_funcs):\n",
        "    result = []\n",
        "    num_of_params = len(param_grid)\n",
        "    for param_config in get_param_config(param_grid, list(param_grid.keys())):\n",
        "        next_param_config = param_config\n",
        "        param_config_dict = dict()\n",
        "        while True:\n",
        "            key, value, next_param_config = next_param_config\n",
        "            param_config_dict[key] = value\n",
        "            param_set_funcs[key](net, value)\n",
        "            if next_param_config is None:\n",
        "                break\n",
        "            \n",
        "        print('Running CV for params {}'.format(param_config_dict))\n",
        "        scores = cross_validation(net, dataset, indices, k, threshold)\n",
        "        mean_score = sum(scores) / len(scores)\n",
        "        print('Got score {} for params {}'.format(mean_score, param_config_dict))\n",
        "        result.append((param_config_dict, mean_score))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jNTN-mYN5QPy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ProteinDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, files):\n",
        "        self._Xes = []\n",
        "        self._yes = []\n",
        "        for xf,yf in files:\n",
        "            X = torch.from_numpy(scsp.load_npz(xf).toarray()).reshape((-1, 21))\n",
        "            y = torch.from_numpy(np.load(yf)['y']).reshape((-1, 1))\n",
        "            assert(X.shape[0] == y.shape[0])\n",
        "            X, y = X.cuda(), y.cuda()\n",
        "            self._Xes.append(X)\n",
        "            self._yes.append(y)\n",
        "        \"\"\"\n",
        "        self._Xes = sorted(self._Xes, key=lambda x: x.shape[0])\n",
        "        self._yes = sorted(self._yes, key=lambda y: y.shape[0])\n",
        "        to_be_collated_Xes = [self._Xes[0]]\n",
        "        to_be_collated_yes = [self._yes[0]]\n",
        "        collated_Xes = []\n",
        "        collated_yes = []\n",
        "        for X, y in zip(self._Xes, self._yes):\n",
        "            assert(X.shape[0] == y.shape[0])\n",
        "            if X.shape[0] == to_be_collated_Xes[-1].shape[0]:\n",
        "                assert(y.shape[0] == to_be_collated_yes[-1].shape[0])\n",
        "                to_be_collated_Xes.append(X)\n",
        "                to_be_collated_yes.append(y)\n",
        "            else:\n",
        "                collated_Xes.append(torch.stack(to_be_collated_Xes))\n",
        "                collated_yes.append(torch.stack(to_be_collated_yes))\n",
        "                to_be_collated_Xes = [X]\n",
        "                to_be_collated_yes = [y]\n",
        "        self._Xes = collated_Xes\n",
        "        self._yes = collated_yes\n",
        "        \"\"\"\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self._Xes[idx]\n",
        "        y = self._yes[idx]\n",
        "        return X.view(1, X.shape[0], X.shape[1]), y.view(1, y.shape[0], y.shape[1])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._Xes)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bu3UKCuX5jdc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FixedWidthFeedForwardNeuralNetwork(nn.Module):\n",
        "    def __init__(self, width, num_outputs, num_layers, activation):\n",
        "        super(FixedWidthFeedForwardNeuralNetwork, self).__init__()\n",
        "        self.linear_layers = [nn.Linear(width, width) for i in range(num_layers-1)]\n",
        "        self.linear_layers.append(nn.Linear(width, num_outputs))\n",
        "        self.activation = activation\n",
        "        for i in range(num_layers):\n",
        "            self.register_parameter('FF' + str(i) + '_weight_', self.linear_layers[i].weight)\n",
        "            self.register_parameter('FF' + str(i) + '_bias_', self.linear_layers[i].bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.activation(self.linear_layers[0](x))\n",
        "        for i in range(1, len(self.linear_layers) - 1):\n",
        "            out = self.activation(self.linear_layers[i](out))\n",
        "        out = self.linear_layers[-1](out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_yuvuMsu5u03",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RecurrentNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=8, output_layer_depth=1,  num_hidden_layers=1, hidden_scale=1.0, ff_scale=0.001, init_lr=1e-3, gamma=0.99, weight_decay=0.1, grad_clip=1.0):\n",
        "        super(RecurrentNeuralNetwork, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_layer_depth = output_layer_depth\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.hidden_scale = hidden_scale\n",
        "        self.ff_scale = ff_scale\n",
        "        self.init_lr = init_lr\n",
        "        self.gamma = gamma\n",
        "        self.weight_decay = weight_decay\n",
        "        self.grad_clip = grad_clip\n",
        "        self.init_layers()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, h = self.rnn_layer(x)\n",
        "        out = self.output_layer(out)\n",
        "        return out\n",
        "\n",
        "    def init_layers(self):\n",
        "        self.rnn_layer = nn.RNN(input_size=self.input_size, \n",
        "                                hidden_size=self.hidden_size,\n",
        "                                nonlinearity='relu',\n",
        "                                num_layers=self.num_hidden_layers,\n",
        "                                batch_first=True, \n",
        "                                bidirectional=True)\n",
        "        self.output_layer = FixedWidthFeedForwardNeuralNetwork(self.hidden_size * 2, 1, self.output_layer_depth, leaky_relu)\n",
        "        self._init_weights_()\n",
        "\n",
        "    def _init_weights_(self):\n",
        "        ff_init_method = nn.init.normal_\n",
        "        hidden_weight_init_method = nn.init.eye_\n",
        "        bias_init_method = nn.init.constant_\n",
        "        for name, param in self.rnn_layer.named_parameters():\n",
        "            if 'weight_hh' in name:\n",
        "                hidden_weight_init_method(param)\n",
        "                with torch.no_grad():\n",
        "                    param.mul_(self.hidden_scale)\n",
        "                param.requires_grad_()\n",
        "            elif 'weight_ih' in name:\n",
        "                ff_init_method(param, std=self.ff_scale)\n",
        "            else:\n",
        "                bias_init_method(param, 0)\n",
        "\n",
        "        for name, param in self.output_layer.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                ff_init_method(param, std=self.ff_scale)\n",
        "            else:\n",
        "                bias_init_method(param, 0)\n",
        "\n",
        "    def predict(self, x):\n",
        "        with torch.no_grad():\n",
        "            out = self.forward(x)\n",
        "            return out\n",
        "\n",
        "    def reset_hidden_size(self, hidden_size):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.init_layers()\n",
        "\n",
        "    def reset_weight_decay(self, weight_decay):\n",
        "        self.weight_decay = weight_decay\n",
        "        self.init_layers()\n",
        "\n",
        "    def reset_gamma(self, gamma):\n",
        "        self.gamma = gamma\n",
        "        self.init_layers()\n",
        "\n",
        "    def reset_output_layer_depth(self, output_layer_depth):\n",
        "        self.output_layer_depth = output_layer_depth\n",
        "        self.init_layers()\n",
        "    \n",
        "    def reset_num_hidden_layers(self, num_hidden_layers):\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.init_layers()\n",
        "\n",
        "    def train(self, dataset, train_indices, validation_indices, model_dir=None, patience=5, warm_start_last_epoch=-1, warm_start_model_params=None):\n",
        "        self.cuda()\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam([{'params' : self.parameters(), 'initial_lr' : self.init_lr}], lr=self.init_lr, weight_decay=self.weight_decay, amsgrad=False)\n",
        "        if warm_start_model_params is not None:\n",
        "            self.load_state_dict(warm_start_model_params['state_dict'])\n",
        "            optimizer.load_state_dict(warm_start_model_params['optimizer'])\n",
        "\n",
        "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, self.gamma)\n",
        "        \n",
        "        self._init_weights_()\n",
        "        \n",
        "        best_validation_pcc_epoch = 0\n",
        "        best_validation_pcc = 0.0\n",
        "        validation_pccs = []\n",
        "        train_pccs = []\n",
        "        print('Starting training at: {}'.format(time.strftime('%Y-%m-%d %H:%M:%S')))\n",
        "        for epoch in range(warm_start_last_epoch + 1, warm_start_last_epoch + 1 + 1000):\n",
        "            scheduler.step()\n",
        "            running_loss = 0.0\n",
        "            random.shuffle(train_indices)\n",
        "            for i in train_indices:\n",
        "                x, y = dataset[i]\n",
        "                optimizer.zero_grad()\n",
        "                y_pred = self.forward(x)\n",
        "                loss = criterion(y_pred, y)\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_value_(self.parameters(), self.grad_clip)\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "\n",
        "            train_pcc = get_avg_pcc(self, dataset, train_indices)\n",
        "            train_pccs.append(train_pcc)\n",
        "\n",
        "            validation_pcc = get_avg_pcc(self, dataset, validation_indices)\n",
        "            validation_pccs.append(validation_pcc)\n",
        "            if validation_pcc > best_validation_pcc:\n",
        "                best_validation_pcc = validation_pcc\n",
        "                best_validation_pcc_epoch = epoch\n",
        "            \n",
        "            print('Epoch: {0:02d} Loss: {1:.6f} Train PCC: {2:.4f} Validation PCC {3:.4f} Time: {4}'.format(\n",
        "                                    epoch, running_loss / len(train_indices), train_pcc, validation_pcc, time.strftime('%Y-%m-%d %H:%M:%S')))\n",
        "\n",
        "\n",
        "            if model_dir is not None:\n",
        "                state = {\n",
        "                        'state_dict' : self.state_dict(),\n",
        "                        'optimizer' : optimizer.state_dict()}\n",
        "                torch.save(state, os.path.join(model_dir, 'net-{0:02d}'.format(epoch)))\n",
        "\n",
        "            if False and epoch - best_validation_pcc_epoch == patience:\n",
        "                break\n",
        "\n",
        "        return train_pccs, validation_pccs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "50ia-MaL52ej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMNeuralNetwork(RecurrentNeuralNetwork):\n",
        "    def __init__(self, input_size, hidden_size=8, output_layer_depth=1,  num_hidden_layers=1, hidden_scale=1.0, ff_scale=0.001, init_lr=1e-3, gamma=0.99, weight_decay=0.1, grad_clip=1.0):\n",
        "        super(LSTMNeuralNetwork, self).__init__(input_size, hidden_size, output_layer_depth, num_hidden_layers, hidden_scale, ff_scale, init_lr, gamma, weight_decay, grad_clip)\n",
        "\n",
        "    def init_layers(self):\n",
        "        self.lstm_layer = nn.LSTM(input_size=self.input_size, \n",
        "                                hidden_size=self.hidden_size,\n",
        "                                #nonlinearity='relu',\n",
        "                                num_layers=self.num_hidden_layers,\n",
        "                                batch_first=True, \n",
        "                                bidirectional=True)\n",
        "        self.output_layer = FixedWidthFeedForwardNeuralNetwork(self.hidden_size * 2, 1, self.output_layer_depth, leaky_relu)\n",
        "        self._init_weights_()\n",
        "\n",
        "    def _init_weights_(self):\n",
        "        #return\n",
        "        ff_init_method = nn.init.xavier_normal_\n",
        "        hidden_weight_init_method = nn.init.orthogonal_\n",
        "        bias_init_method = nn.init.constant_\n",
        "        for name, param in self.lstm_layer.named_parameters():\n",
        "            if 'weight_hh' in name:\n",
        "                hidden_weight_init_method(param)\n",
        "                with torch.no_grad():\n",
        "                    param.mul_(self.hidden_scale)\n",
        "                param.requires_grad_()\n",
        "            elif 'weight_ih' in name:\n",
        "                ff_init_method(param)\n",
        "            else:\n",
        "                bias_init_method(param, 0)\n",
        "\n",
        "        for name, param in self.output_layer.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                ff_init_method(param)\n",
        "            else:\n",
        "                bias_init_method(param, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, h = self.lstm_layer(x)\n",
        "        out = self.output_layer(out)\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mHgoes7c566d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPk9-QYoA7oX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_X09Sl2BIGS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WuFS_m5ZBOxA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "protein_list_file = drive.CreateFile({'id' : '1B8jJtU2sZGEZgI66Wn3qzjROG6Bqiusi'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FlNH5s-yCDhH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "protein_list_file.GetContentFile('protein_list.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mkmOWsjWCMgu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rnn_inputs_compressed_file = drive.CreateFile({'id' : '1URxykv0RfgC3f0XJLteZrQ8lwTILgaZZ'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HKLq7YIvCf6p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rnn_inputs_compressed_file.GetContentFile('rnn_inputs.tar.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ow3R0LfuCp_5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar xzvf rnn_inputs.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b6rqjx_tC0m9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b53cb5b1-9e44-4e52-99b3-158fd5bd8502"
      },
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(precision=2, linewidth=140)\n",
        "torch.manual_seed(42)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe2202a3330>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "pJzjteirDMTX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('protein_list.txt') as protein_list_file:\n",
        "    protein_list = protein_list_file.read().split()\n",
        "    protein_list = [s.upper().strip() for s in protein_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ga8nNcVODdhz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_files = []\n",
        "y_files = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z5KMUb39Dknr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for protein in protein_list:\n",
        "    X_files.append(os.path.join('rnn_inputs', 'X_' + protein + '_rnn_.npz'))\n",
        "    y_files.append(os.path.join('rnn_inputs', 'y_' + protein + '_rnn_.npz'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9KzSUhlgDxyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6eb6c07e-a4cb-473e-a172-2c4692503f8b"
      },
      "cell_type": "code",
      "source": [
        "files = list(zip(X_files, y_files))\n",
        "dataset = ProteinDataset(files)\n",
        "print('Dataset init done ', len(dataset))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset init done  3108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YlP2vjS_D4yd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indices = list(range(len(dataset)))\n",
        "random.seed(42)\n",
        "random.shuffle(indices)\n",
        "#indices = indices[:100]\n",
        "train_indices = indices[:int(0.8 * len(indices))]\n",
        "validation_indices = indices[int(0.8 * len(indices)):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "imeHLPwuFIn3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "warm_start_model_params = None\n",
        "warm_start_last_epoch = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PdDCL5DPJSJV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "init_lr = 2.0 ** -7\n",
        "momentum = 0.9\n",
        "weight_decay = 1e-4\n",
        "gamma = 0.9\n",
        "hidden_size = 64\n",
        "hidden_scale = 1.0\n",
        "num_hidden_layers = 1\n",
        "output_layer_depth = 8\n",
        "ff_scale = 0.6\n",
        "grad_clip = 10.0\n",
        "nesterov = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K1EnAPy-JpZN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = LSTMNeuralNetwork(21,\n",
        "        hidden_size=hidden_size,\n",
        "        num_hidden_layers=num_hidden_layers,\n",
        "        output_layer_depth=output_layer_depth,\n",
        "        hidden_scale=hidden_scale, ff_scale=ff_scale, \n",
        "        init_lr=init_lr, gamma=gamma, weight_decay=weight_decay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NMnjthyDKDF-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Omd_PAAlM4xn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnYQBH9LJxSD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net.train(dataset, train_indices, validation_indices, patience=20, model_dir='models', warm_start_last_epoch=warm_start_last_epoch,\n",
        "        warm_start_model_params=warm_start_model_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_yKG1RSWSX4J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}